type: "RulikGpu"

# Input image. (Image)
input_stream: "IMAGE:input_image"

# Complexity of hand landmark and palm detection models: 0 or 1. Accuracy as
# well as inference latency generally go up with the model complexity. If
# unspecified, functions as set to 1. (int)
input_side_packet: "MODEL_COMPLEXITY:model_complexity"

# The output_image  image. (Image)
output_stream: "IMAGE:output_image"

# Extra outputs (for debugging, for instance).
# Detected palms. (std::vector<Detection>)
output_stream: "PALM_DETECTIONS:palm_detections"

# Detected faces. (std::vector<Detection>)
# NOTE: there will not be an output packet in the DETECTIONS stream for this
# particular timestamp if none of faces detected. However, the MediaPipe
# framework will internally inform the downstream calculators of the absence of
# this packet so that they don't wait for it unnecessarily.
output_stream: "FACE_DETECTIONS:face_detections"

node {
  calculator: "FlowLimiterCalculator"
  input_stream: "input_image"
  input_stream: "FINISHED:output_image"
  input_stream_info: {
    tag_index: "FINISHED"
    back_edge: true
  }
  output_stream: "throttled_image"
  options: {
    [mediapipe.FlowLimiterCalculatorOptions.ext] {
      max_in_flight: 1
      max_in_queue: 1
    }
  }
}

# Converts Image to GpuBuffer for SelfieSegmentationGpu and PalmDetectionGpu.
node {
  calculator: "FromImageCalculator"
  input_stream: "IMAGE:throttled_image"
  output_stream: "IMAGE_GPU:gpu_buffer"
  output_stream: "SOURCE_ON_GPU:is_gpu_image"
}


# Flip image for selfie segmentation and palm detection
node: {
  calculator: "ImageTransformationCalculator"
  input_stream: "IMAGE_GPU:gpu_buffer"
  input_stream: "FLIP_VERTICALLY:is_gpu_image"
  output_stream: "IMAGE_GPU:gpu_buffer_flip"
}

# Detects palms.
node {
  calculator: "PalmDetectionGpu"
  input_side_packet: "MODEL_COMPLEXITY:model_complexity"
  input_stream: "IMAGE:gpu_buffer_flip"
  output_stream: "DETECTIONS:palm_detections"
}

# Subgraph that performs face detection. # calculator: "FaceDetectionShortRangeImage"  
node {  
  calculator: "FaceDetectionFullRangeImage"  
  input_stream: "IMAGE:throttled_image"
  output_stream: "DETECTIONS:face_detections"
}



# Create model selection for Selfie segmentation
node {
  calculator: "ConstantSidePacketCalculator"
  output_side_packet: "PACKET:selfie_model_selection"
  node_options: {
    [type.googleapis.com/mediapipe.ConstantSidePacketCalculatorOptions]: {
      packet { int_value: 1 }
    }
  }
}

# Subgraph that performs Selfie segmentation.
node {
  calculator: "SelfieSegmentationGpu"
  input_stream: "IMAGE:gpu_buffer_flip"
  input_side_packet: "MODEL_SELECTION:selfie_model_selection"
  output_stream: "SEGMENTATION_MASK:segmentation_mask"
}


# Colors the selfie segmentation with the color specified in the option.
node {
  calculator: "RecolorCalculatorV1"
  input_stream: "IMAGE_GPU:gpu_buffer_flip"
  input_stream: "MASK_GPU:segmentation_mask"
  output_stream: "IMAGE_GPU:output_gpu_image"
  node_options: {
    [type.googleapis.com/mediapipe.RecolorCalculatorOptions] {
      color { r: 0 g: 170 b: 0 }
      mask_channel: RED
      invert_mask: true
      adjust_with_luminance: false
    }
  }
}

# Flip image back from colored selfie segmentation
node: {
  calculator: "ImageTransformationCalculator"
  input_stream: "IMAGE_GPU:output_gpu_image"
  input_stream: "FLIP_VERTICALLY:is_gpu_image"
  output_stream: "IMAGE_GPU:output_gpu_image_flip"
}

node {
  calculator: "ToImageCalculator"
  input_stream: "IMAGE_GPU:output_gpu_image_flip"
  output_stream: "IMAGE:output_image"
}